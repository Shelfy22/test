{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shelfy22/test/blob/main/RAG_Web_Search_01_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPbWrXs0IGHk"
      },
      "source": [
        "# Концепты использования RAG (Retrieval-Augmented Generation)\n",
        "## Поиск в интернете и RAG\n",
        "\n",
        "Как результаты поиска в интернете использовать в качестве Базы Знаний для RAG?\n",
        "\n",
        "DuckDuckGo Search: https://python.langchain.com/v0.1/docs/integrations/tools/ddg/\n",
        "\n",
        "Приглашаю в Телеграм общаться по этой теме: https://t.me/AiExp01"
      ],
      "id": "RPbWrXs0IGHk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка библиотек, вспомогательные функции"
      ],
      "metadata": {
        "id": "0z4vXw8wLhv9"
      },
      "id": "0z4vXw8wLhv9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du1VqIAxIGHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a189308-70d8-497d-ba39-b577c40732a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/362.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m358.4/362.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.13 (from langchain-community)\n",
            "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.30 (from langchain-community)\n",
            "  Downloading langchain_core-0.2.34-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.13->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (2.8.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.30->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.27.0)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain-community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.34-py3-none-any.whl (393 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.14 langchain-community-0.2.12 langchain-core-0.2.34 langchain-text-splitters-0.2.2 langsmith-0.1.104 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.2.11-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting primp>=0.6.1 (from duckduckgo-search)\n",
            "  Downloading primp-0.6.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Downloading duckduckgo_search-6.2.11-py3-none-any.whl (27 kB)\n",
            "Downloading primp-0.6.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-6.2.11 primp-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade openai\n",
        "!pip install langchain-community\n",
        "!pip install --upgrade duckduckgo-search"
      ],
      "id": "du1VqIAxIGHq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Suh_hh29IGHr"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем API ключ\n",
        "from google.colab import userdata\n",
        "OPEN_AI_API_KEY = userdata.get('OpenAI_API_KEY')\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_API_KEY\n",
        "# LL_MODEL='gpt-4o'\n",
        "LL_MODEL='gpt-3.5-turbo'\n",
        "# LL_MODEL='gpt-4o'"
      ],
      "id": "Suh_hh29IGHr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Данные для запроса, системный промпт"
      ],
      "metadata": {
        "id": "ZTPWToSHf5BN"
      },
      "id": "ZTPWToSHf5BN"
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = 'сравнение фреймворков LangChain и Llamaindex'\n",
        "\n",
        "system_content = 'Ты специолист по LLL (Large Language Model) и отвечаешь на вопросы новичков'"
      ],
      "metadata": {
        "id": "rcolZO3hJUdW"
      },
      "id": "rcolZO3hJUdW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выполняем запрос в LLM без поиска в web"
      ],
      "metadata": {
        "id": "ehzORE_vY-HT"
      },
      "id": "ehzORE_vY-HT"
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPEN_AI_API_KEY)\n",
        "def gpt_request(user_content, system_content):\n",
        "  response = client.chat.completions.create(\n",
        "    model=LL_MODEL,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_content}, # <-- This is the system message that provides context to the model\n",
        "      {\"role\": \"user\", \"content\": user_content}     # <-- This is the user message for which the model will generate a response\n",
        "    ]\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "80gEHvx0M59P"
      },
      "id": "80gEHvx0M59P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt_request(search_query, system_content)\n",
        "print (response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6sw25gRM-XW",
        "outputId": "48b8d156-3dd5-4442-bd67-a106dcd823fa"
      },
      "id": "E6sw25gRM-XW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Извините, но я не могу дать информацию о фреймворках LangChain и Llamaindex, так как они мне неизвестны. Возможно, вы имели в виду другие фреймворки или платформы? Если у вас есть другие вопросы по LLL или другим темам, буду рад помочь!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выполняем поиск в Интернете"
      ],
      "metadata": {
        "id": "_NU8pGtXZ86a"
      },
      "id": "_NU8pGtXZ86a"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "search = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "ojnyPxKuR1nI"
      },
      "id": "ojnyPxKuR1nI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = search.run(search_query)\n",
        "print(search_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKofGpTXSBcO",
        "outputId": "102193ce-7854-42fc-b1ac-481adade6a31"
      },
      "id": "JKofGpTXSBcO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain focuses on building complex workflows and interactive applications, while LlamaIndex emphasizes seamless data integration and dynamic data management. This article provides a comprehensive comparison between these two frameworks, exploring their unique features, tools, and ecosystems. LlamaIndex has very cool features like reordering results with cross encoders, or lost in the middle support, but makes some basic things like sentence transformers unnecessary hard (as reported. LangChain, allows easy integration, and provides both RAG and other LLM components out of the box. LlamaIndex vs LangChain: To truly understand the positioning of LlamaIndex in the AI landscape, it's essential to compare it with LangChain, another prominent framework in the domain. Introduction In the rapidly evolving landscape of artificial intelligence and natural language processing, two frameworks have emerged as powerful tools for developers working with Large Language Models (LLMs): LlamaIndex and LangChain. This blog post aims to provide a comprehensive comparison of LlamaIndex vs LangChain, exploring their key features, use cases, and practical applications. By ... LlamaIndex and LangChain are powerful frameworks for building LLM-powered applications, each with its own strengths and focus areas. LlamaIndex excels in search and retrieval tasks, offering streamlined data indexing and querying capabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Готовим промпт с учетом результатов поиска"
      ],
      "metadata": {
        "id": "mMJ2DTO0fHe7"
      },
      "id": "mMJ2DTO0fHe7"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_openai(search_results):\n",
        "    # print(f'search_results={search_results}')\n",
        "    prompt = (f\"Ответьте на вопрос по-русски, используя только приведенный ниже контекст.\\n\" +\n",
        "        \"Каждое предложение начинай с новой сторки\\n\"+\n",
        "        f\"Контекст:\\n{search_results}\"\n",
        "    )\n",
        "    # Возвращаем сгенерированныц промпт.\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "a25o_LQZHoqs"
      },
      "id": "a25o_LQZHoqs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = create_prompt_openai(search_results)\n",
        "print (prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QVruoe3aa_b",
        "outputId": "788c3421-8610-4162-af20-d0698169f6e6"
      },
      "id": "7QVruoe3aa_b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ответьте на вопрос по-русски, используя только приведенный ниже контекст.\n",
            "Каждое предложение начинай с новой сторки\n",
            "Контекст:\n",
            "LangChain focuses on building complex workflows and interactive applications, while LlamaIndex emphasizes seamless data integration and dynamic data management. This article provides a comprehensive comparison between these two frameworks, exploring their unique features, tools, and ecosystems. LlamaIndex has very cool features like reordering results with cross encoders, or lost in the middle support, but makes some basic things like sentence transformers unnecessary hard (as reported. LangChain, allows easy integration, and provides both RAG and other LLM components out of the box. LlamaIndex vs LangChain: To truly understand the positioning of LlamaIndex in the AI landscape, it's essential to compare it with LangChain, another prominent framework in the domain. Introduction In the rapidly evolving landscape of artificial intelligence and natural language processing, two frameworks have emerged as powerful tools for developers working with Large Language Models (LLMs): LlamaIndex and LangChain. This blog post aims to provide a comprehensive comparison of LlamaIndex vs LangChain, exploring their key features, use cases, and practical applications. By ... LlamaIndex and LangChain are powerful frameworks for building LLM-powered applications, each with its own strengths and focus areas. LlamaIndex excels in search and retrieval tasks, offering streamlined data indexing and querying capabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выполняем запрос в LLM использую результаты поиска в web"
      ],
      "metadata": {
        "id": "diTFjhdOfa4T"
      },
      "id": "diTFjhdOfa4T"
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt_request(prompt, system_content)\n",
        "print (response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz4qAcyPeLEE",
        "outputId": "7217f1a6-d037-4451-d3d9-43d3aec3e6c3"
      },
      "id": "Sz4qAcyPeLEE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain сосредоточен на построении сложных рабочих процессов и интерактивных приложений, в то время как LlamaIndex акцентирует внимание на безупречной интеграции данных и динамичном управлении данными.\n",
            "\n",
            "Этот обзор представляет собой всестороннее сравнение между этими двумя фреймворками, исследуя их уникальные особенности, инструменты и экосистемы.\n",
            "\n",
            "LlamaIndex имеет очень крутые функции, такие как переупорядочивание результатов с помощью кросс-кодировщиков, или поддержка «потерян в середине», но делает некоторые базовые вещи, такие как преобразователи предложений, ненужно сложными (как сообщается).\n",
            "\n",
            "LangChain позволяет легкую интеграцию и предоставляет как RAG, так и другие компоненты LLM \"из коробки\".\n",
            "\n",
            "Сравнение LlamaIndex и LangChain: Для полного понимания позиционирования LlamaIndex в области искусственного интеллекта, необходимо сравнить его с LangChain, еще одним важным фреймворком в этой сфере. \n",
            "\n",
            "В быстро меняющемся ландшафте искусственного интеллекта и обработки естественного языка два фреймворка выделяются как мощные инструменты для разработчиков, работающих с большими языковыми моделями (LLM): LlamaIndex и LangChain.\n",
            "\n",
            "Этот пост в блоге направлен на предоставление всестороннего сравнения LlamaIndex против LangChain, исследуя их ключевые особенности, применения и практические применения.\n",
            "\n",
            "LlamaIndex и LangChain - мощные фреймворки для создания приложений, работающих на основе LLM, каждый со своими сильными сторонами и областями фокусировки. \n",
            "\n",
            "LlamaIndex выдающийся в задачах поиска и извлечения, предлагая упрощенные возможности индексации и запросов данных.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Внимание:\n",
        "\n",
        "1. Если вы испытываете проблемы с просмотром ранее опубликованного видео в связи с замедлением Youtube, пишите в кометы под нужным постом в Телеграм - и я залью туда это видео.\n",
        "2. Приглашаю в Телеграм общаться по этой теме: https://t.me/AiExp01\n",
        "3. Чат находится здесь: https://t.me/AiExp02\n",
        "4. Что еще изучить и посмотреть:\n",
        "\n",
        "*   LlamaIndex https://www.youtube.com/watch?v=myGdYwP83D8&list=PLAzpexGM7JahXip0jNyDEJwPj-wySj3Ix\n",
        "*   Концепты использования OpenAI API (API ChatGPT)\n",
        "Playlist: https://www.youtube.com/watch?v=FoLquyNFE_c&list=PLAzpexGM7JagNMDIWUsoO8fbTwbY82ZEN\n",
        "*   Концепты использования RAG (Retrieval-Augmented Generation)\n",
        "Playlist: https://www.youtube.com/watch?v=NkjkqsLCweQ&list=PLAzpexGM7Jai1qgfxMkY-6ivOft-7dh8Q\n"
      ],
      "metadata": {
        "id": "GRNPSxZ9IMrM"
      },
      "id": "GRNPSxZ9IMrM"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}